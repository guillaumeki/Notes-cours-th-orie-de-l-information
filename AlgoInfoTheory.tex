La théorie algorithmique de l'information, initiée par Kolmogorov, Solomonov et Chaitin dans les années 1960, vise à quantifier et qualifier le contenu en information d'un ensemble de données, en utilisant la théorie de la calculabilité et la notion de machine universelle de Turing.

	\subsection{Mesures de l'information}

\begin{definition}{Machine}
%comp. = composition ?
\par Composition de fonctions partielles prenant une chaîne et renvoyant une chaîne.
\end{definition}

\begin{definition}{M-Description}
\par Soit une machine $M$ telle que $M(\sigma) = x$. $\sigma$ est une $M-Description$ de $x$.
\end{definition}

\paragraph{Chaîne binaire et nombre entier} Les fonctions utilisées sont de $\mathbb{N}$ dans $\mathbb{N}$, mais on représentera les nombres entiers sous forme de chaînes binaires. Ainsi, cela devient des fonctions de $\{0,1\}^*$ dans $\{0,1\}^*$.
\par Ainsi, $\sigma$ sera la représentation sous forme de chaîne binaire de l'entier naturel $n$. La représentation binaire de $n+1$ est $1\sigma$. $n = nombre(\sigma)$ et $\sigma = chaine(n)$.

\begin{definition}{$chaine(n)$}
\par $$ rec\_chaine(n) = 
			\left \{
				\begin{array}{ll}
					rec\_chaine(n/2).(n~mod~2) & si~ n > 1 \\
					1 & si~ n = 1 \\
					0 & sinon \\
				\end{array}
			\right.
	$$
\par $$ chaine(n) = 
			\left \{
				\begin{array}{ll}
					rec\_chaine(n-1) & si~ n > 0 \\
					\epsilon & sinon \\
				\end{array}
			\right.
	$$
\end{definition}

\begin{definition}{$nombre(\sigma)$}
\par $$ rec\_nombre(n) = 
			\left \{
				\begin{array}{ll}
					2*rec\_nombre(u) & si~ \sigma = u.0 \\
					2*rec\_nombre(u)+1 & si~ \sigma = u.1 \\
					0 &sinon \\
				\end{array}
			\right.
	$$
\par $$ nombre(n) = 
			\left \{
				\begin{array}{ll}
					rec\_nombre(\sigma)+1 & si~ \sigma \not= \epsilon \\
					0 & sinon \\
				\end{array}
			\right.
	$$
\end{definition}

\begin{example}
\begin{itemize}
\item La chaîne $10$ correspond au nombre $5$.
\item $\epsilon$ correspond à $0$.
\end{itemize}
\end{example}

\begin{definition}{Complexité}
\par La complexité est la taille de la plus petite chaîne $\sigma$ permettant d'engendrer la chaîne $x$ pour une machine $M$.
\par $$C_M(x) = min\{|\sigma|:M(\sigma) = x\}$$
\par $min \emptyset = \inf$.
\end{definition}

	\subsection{Jetons de Rosza}
		\subsubsection{Fonctions récursives primitives}

\begin{definition}
En théorie de la calculabilité, une fonction récursive primitive est une fonction construite à partir de la fonction nulle, fonction successeur, fonctions projections et les schémas primitifs de récursion et de composition. Ces fonctions constituent un sous-ensemble strict des fonctions récursives.
\par Elles ont été initialement analysées par la mathématicienne Rózsa Péter.
\par On construit les fonctions récursives primitives par induction en partant des trois fonctions de base :
\begin{itemize}
	\item La fonction identiquement nulle ;
	\item La fonction successeur : $Succ(t)=t+1$ ;
	\item Les projections : $(x_{1},...,x_{k})\rightarrow x_{i}$.
\end{itemize}
et en itérant les deux constructions suivantes :
\begin{itemize}
	\item La composition de fonctions : 
si $g_{1}, g_{2}, ..., g_{k}$ sont récursives primitives sur $\mathbb {N} ^{n}$ 
et si $h$ est récursive primitive sur $\mathbb {N} ^{k}$, toutes déjà définies,
alors la fonction $f=h(g_{1},...,g_{k})$ est une fonction récursive primitive définie sur $\mathbb {N} ^{n}$ ;

	\item La définition récursive d'une fonction : 
si $g$ est récursive primitive sur $\mathbb {N} ^{n}$, et $h$ récursive primitive sur ${\mathbb  N}\times {\mathbb  N}\times {\mathbb  N}^{n}$, on définit une nouvelle fonction récursive primitive $f$ sur ${\mathbb  N}^{{n+1}}$ par :
	\begin{itemize}
		\item $f(0,\vec y) = g(\vec y)$
		\item $ f(Succ(x),\vec y) = h(x,f(x,\vec y),\vec y)$.
	\end{itemize}
\end{itemize}
\end{definition}

\begin{definition}{Jetons de bases}
\begin{itemize}
\item \Zero : $~ \mapsto 0$
\item \Successor : $~x \mapsto x+1$
\item \Identity : $~x \mapsto x$
\end{itemize}
\end{definition}

\begin{definition}{Constructeurs}
\begin{itemize}
\item \Left : $~x, \bar{y} \mapsto \bar{y}$
\item \Right : $~\bar{x}, y \mapsto \bar{x}$
\item Soient une fonction $f$ récursive primitive d'arité $k$ et les fonctions récursives primitives $g_1,g_2,\ldots,g_k$ d'arité $n$. \par $\Composition(f,g_1,g_2,\ldots,g_k)(\bar{x}) = f(g_1(\bar{x}),g_2(\bar{x}),\ldots,g_k(\bar{x}))$.
\item Soit $f$ une fonction récursive primitive d'arité $n$ et $g$ une fonction récursive primite d'arité $n+2$. On obtient, la fonction récursive primitive d'arité $n+1$ :
\par $\Recurse(f,g)(x, \bar{y}) = \left\{
	\begin{array}{ll}
		f(\bar{y}) & si ~x = 0 \\
		g(x-1,\Recurse(f,g)(x-1, \bar{y}),\bar{y}) & sinon
	\end{array} \right.
	$
\end{itemize}
\end{definition}

	\subsubsection{Fonctions $\mu$-recursives}
	
\begin{definition}
En informatique et en mathématiques, le terme fonction récursive (ou fonction $\mu$-recursive) désigne une classe de fonctions calculables, autrement dit de fonctions dont les valeurs peuvent être calculées à partir de leurs paramètres par un processus mécanique.
\par Les fonctions récursives primitives sont une sous-partie stricte de l'ensemble des fonctions récursives, elles ne permettent pas de calculer tout ce qui est calculable. Il est nécessaire d'y ajouter une fonction nommée $\mu$.
\end{definition}

\begin{definition}{Fonction $\mu$}
\par $\Mu(f) \bar{y} \mapsto min\{x : f(x,\bar{y}) = 0\}$.
\par À noter : contrairement aux fonctions récursives primitives, $\mu$ n'est pas définie sur tout son domaine : il s'agit d'une fonction récursive partielle.
\end{definition}

	\subsubsection{Interpréteur de jetons en ligne}

\href{http://rozsa-tokens.info/}{Interpréteur de jetons de Rozsa en ligne : http://rozsa-tokens.info/}

\subsection{Conditionnal information}

\begin{definition}
$$\mathbb{V}^2(0^{e-1}1\sigma,y)=\phi_e(<\sigma,y>)$$
\end{definition}

\begin{definition}
$$C(x|y) = min\{|\sigma|:\mathbb{V}^2(\sigma,y)=x\}$$
\end{definition}

\subsection{Lien entre C et K}

\par K est une complexité qui est plus naturelle (parce qu'on prend en compte qu'il y a de l'information dans la longueur).
\par Pour prouver $K(x) \leqslant^+ K(|x|)+|x|$, on a construit une machine sans préfixe N qui tente de décomposer l'entrée $\tau$ en $\tau=\sigma\rho$ tel que $\sigma = |\rho|$ : on va pouvoir en déduire un lien entre C et K.

\begin{theorem}
$$K(x)\leqslant K(C(x))+C(x)$$.
\end{theorem}

\begin{theorem}
$$K(X) \leqslant^+ K(|x|)+|x|$$
\end{theorem}

\begin{theorem}
$$C(X) \leqslant^+ K(x) \leqslant^+ C(x) + 2 log(C(x)) \leqslant^+ C(x)+2log(|x|)$$
\end{theorem}

\begin{proof}
On sait que $C(x) \leqslant^+ K(x).$
\end{proof}

\begin{theorem}
$$\forall x,y, C(xy) \leqslant^+ K(x) + C(y)$$
\end{theorem}

\begin{theorem}
$$abs(C(x)-C(y)) \leqslant^+ K(abs(x-y)) \leqslant^+ 2log(abs(x-y))$$
\end{theorem}

\begin{theorem}
$$C(x) =^+ K(x|C(x))$$
\end{theorem}

\begin{corollary}
$$C(xy) \leqslant^+ C(x) + 2 log(C(x))+C(y)$$
\end{corollary}

\subsection{Coding efficiently a pair - some mutual information}

\begin{theorem}
$C(x,y)\leqslant^+ C(x) + 2~ log~C(x) + C(y|x)$
\end{theorem}

\begin{theorem}
$C(x,y)=^+ C(x) + C(y|x) +O(log~n)$
\par $|x|,|y| \leqslant n$
\end{theorem}

\begin{definition}
$I(x:y)=C(y)-C(y|x)$
\par information content of y in x
\end{definition}

\begin{theorem}
$C(x,y)=^+ C(x)+C(y|x)+O(log~C(x,y))$
\end{theorem}

\begin{theorem}
$\exists c, I(x:y) \geqslant c$
\end{theorem}

\begin{theorem}
$C(y|X) = C(x,y) - C(x) + O(log(C(x,y)))$
\end{theorem}

\begin{corollary}
$I(x:y) = C(x) + C(y) - C(x,y) + O(log(C(x,y))$
\end{corollary}

\begin{corollary}
$I(x:y) = I(y:x) + O(log(C(x,y)))$
\end{corollary}

\begin{theorem}
$I(x:y)+C(x|y) \approx C(x)$
\end{theorem}

\begin{theorem}
$C(x|y) + I(x:y)+C(y|x) \approx C(x,y)$
\end{theorem}

\paragraph{Problem}$\exists x,y,I(x:y) ~large, \not\exists z, C(z|x) \approx 0, C(z|y) \approx 0, C(z) \approx I(x:y)$

\subsection{Kolomogorov au secours de la théorie des nombres premiers}

\par For any $n$, there is an incompressible string $x$ of length $n$. Even, $C(x) \geqslant |x|$.

\begin{definition}
Incompressible: $C(x) \geqslant^+ [x|$
\end{definition}

\begin{theorem}
Théorème des nombres premiers : $\pi_n \leqslant n~log(n)$
\end{theorem}

\begin{theorem}
$\pi_i = O(i~log(i)^2)$
\end{theorem}

\begin{theorem}
$\pi_i = O(i(log~i)^{(1+\epsilon)}), \epsilon > 0$
\end{theorem}

\subsection{À quoi ça sert ?}

\begin{theorem}
Il y a une infinité de nombres premiers.
\end{theorem}

\begin{theorem}
Presque letheorèeme des nombres premiers.
\end{theorem}

\begin{theorem}
Strong law of large numbers : proportion du nombre de 1 tend vers 1/2 à l'infini.
\end{theorem}

\begin{theorem}
Law of iterated logarithm :
$$|p_n^{ones}-\frac{1}{2}| \leqslant (1 + \epsilon) \sqrt{\frac{ln (ln(n))}{2n}}$$
\end{theorem}

\begin{definition}
Razoir d'Occam : moins on a de données pour décrire un système, mieux c'est
\end{definition}


\paragraph{Paradoxe de Berry} The minimal natural number that cannot be defined by at most fourteen Englsh word
\begin{definition}
Trous noirs - toute chose est juste un ensemble de bits (Wheeler). Every physical quantity, every it, derives its ultimate significance from bits, binary yes-or-nos indciations"
\par "it from the bit"
\end{definition}

\begin{theorem}
Théorème d'incomplétude Gödel (premier)
\par Il existe des propositions vraies mais indémontrables
\end{theorem}

\begin{theorem}
Deuxième théorème d'incomplétude de Gödel
\par Cons(T) est l'une d'entre elles
\end{theorem}

\begin{definition}
Hereditary base notations
\par Séquence de Goodstein
\end{definition}

\par Pas prouvable dans la théorie de Peano mais vrai.

\begin{theorem}
PA ne prouve pas $\forall n, G(n) \rightarrow 0$.
\end{theorem}